# ðŸ§  Databricks Apps Demo  
**Build, serve, and interact with Databricks Data and AI through real applications.**

---

### ðŸš€ What It Is  
A working example of how to build **full-stack data apps** powered by the **Databricks Lakehouse** â€” combining:  
- A **Python (Dash)** front-end client  
- Shared **data modules** for Delta, permissions, and metadata  

It shows how to go from **data â†’ API â†’ UI â†’ AI** all in one repo.

<p align="center">
  <a href="https://www.youtube.com/watch?v=ZbErw3mDh4E">
    <img src="https://img.youtube.com/vi/ZbErw3mDh4E/hqdefault.jpg" alt="Watch the video">
  </a>
</p>


---

### ðŸ’¡ Value Proposition  
Databricks isnâ€™t just for data pipelines â€” itâ€™s an **application platform**.  
This project demonstrates how to:  
- Build **interactive apps** backed by Delta and Databricks APIs  
- Expose **secure, production-ready endpoints**  
- Enable **real-time insights and GenAI features** directly on Lakehouse data  

---

### ðŸ§© Structure  
```bash
DatabricksAppsDemo/
â”œâ”€â”€ server/       # Rust Axum API
â”‚   â”œâ”€â”€ data/     # Shared Rust modules (api_client, delta, metastore, permissions)
â”‚   â””â”€â”€ src/
â”œâ”€â”€ client/       # Python Dash app
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ components/
â””â”€â”€ notebooks/    # Databricks setup / data prep
```

### Getting Started 
```
# Clone the repo
git clone https://github.com/rchynoweth/DatabricksAppsDemo.git
cd DatabricksAppsDemo

# Create Anaconda Environment
conda create -n DatabricksApps python=3.11 -y
conda activate DatabricksApps

# Deploy to Databricks
databricks apps deploy hello-world --source-code-path /Workspace/Users/rchynoweth@invisocorp.com/databricks_apps/file-uploader-app

# Keep local changes in sync 
databricks sync --watch . /Workspace/Users/rchynoweth@invisocorp.com/databricks_apps/file-uploader-app

```
